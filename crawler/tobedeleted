import urllib,Image,cStringIO
#from pymongo import MongoClient

"""def myfunction(query):
    def get_soup(url,header):
        return BeautifulSoup(urllib2.urlopen(urllib2.Request(url,headers=header)),'html.parser')

    query= query.split()
    query='+'.join(query)
    url="https://www.google.co.in/search?q="+query+"&source=lnms&tbm=isch"
    header={'User-Agent':"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.134 Safari/537.36"}
    soup = get_soup(url,header)
    ActualImages = []
    for a in soup.find_all("div",{"class":"rg_meta"}):
                link , Type =json.loads(a.text)["ou"]  ,json.loads(a.text)["ity"]
                ActualImages.append((link,Type))
    for i , (img , Type) in enumerate( ActualImages[0:2]):
            return img"""
def myfunction2(URL,line):
	try:
		file = cStringIO.StringIO(urllib.urlopen(URL).read())
		img = Image.open(file).convert('RGB')
		height = 100
		width = 100
		img=img.resize((width, height), Image.ANTIALIAS)
		return img
	except:
		print line
		return -1

with open("subcatimglinks1",'r') as fd,open("subcatimglinks2","w") as fd1:
	for line in fd:
		line=line.split(" : ")
		img=myfunction2(line[1],line[0])
		if img==-1:
			fd1.write(line[0]+" : "+line[1])
			continue
		name="static/crawler/media/"+str(line[0])+".jpg"
		name1="crawler/media/"+str(line[0])+".jpg"
		print name
		img.save(name)
		fd1.write(line[0]+" : "+name1+"\n")